{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Details:\n",
    "\n",
    "* Data Normalization: in this tutorial we have selected three different normalization methods, including the QuantileTransformer (check out the documentation)..\n",
    "\n",
    "* Dimensionality Reduction: we selected Principal Component Analysis (PCA) and a univariate feature selection algorithm as possible candidates.\n",
    "\n",
    "* Regression: we apply a simple regularized linear method, although the method is easily extendable to other learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "pca = PCA()\n",
    "ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    \n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('regressor', Ridge())\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('regressor', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing score:  -5573.01401859\n"
     ]
    }
   ],
   "source": [
    "print('Testing score: ', pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0026455,  1.0026455,  1.0026455,  1.0026455,  1.0026455,\n",
       "        1.0026455,  1.0026455,  1.0026455,  1.0026455,  1.0026455,\n",
       "        1.0026455,  1.0026455,  1.0026455])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing pipeline to represent the steps\n",
    "\n",
    "pipe.steps[1][1].explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.24262291, -5.63727879, -3.07670887, -1.43650915, -1.63554129,\n",
       "        2.03750121,  1.00838457, -0.52069999, -2.32708928, -0.5815485 ,\n",
       "       -1.3458464 , -1.386344  ,  0.13674465])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps[2][1].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://iaml.it/user/pages/05.blog/optimizing-sklearn-pipelines/images/pipeline-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On every object within the pipeline the methods `fit_transform` are invoked during training, while `transform (or predict)` are called during test. So far using pipelines is just a matter of code cleaness and minimization. Now let's jump into model's hyper-parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Tuning (Base Version)\n",
    "\n",
    "Interested in tuning the following:\n",
    "* `n_components` of PCA()\n",
    "* `alpha` of Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features_to_test = np.arange(1, 11)\n",
    "alpha_to_test = 2.0**np.arange(-6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.56250000e-02,   3.12500000e-02,   6.25000000e-02,\n",
       "         1.25000000e-01,   2.50000000e-01,   5.00000000e-01,\n",
       "         1.00000000e+00,   2.00000000e+00,   4.00000000e+00,\n",
       "         8.00000000e+00,   1.60000000e+01,   3.20000000e+01])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_to_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dict of Params\n",
    "\n",
    "It's possible to notice that the two parameters are correlated, and should be optimized in combination. That is, a variation in the number of PCA components might imply a variation in the regularization factor, and viceversa. Thereby, it is important to evaluate all their possible combinations, and this is where the pipeline module really supports us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \n",
    "    'reduce_dim__n_components': n_features_to_test,\n",
    "    'regressor__alpha': alpha_to_test\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV on Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "gridsearch = GridSearchCV(pipe, params, verbose=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score is:  -6316.70817709\n"
     ]
    }
   ],
   "source": [
    "print('Final score is: ', gridsearch.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are: \n",
      " {'reduce_dim__n_components': 10, 'regressor__alpha': 0.015625}\n"
     ]
    }
   ],
   "source": [
    "print('Best params are: \\n', gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Pipeline Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalers_to_test = [StandardScaler(), RobustScaler(), QuantileTransformer()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'scaler': scalers_to_test,\n",
    "        'reduce_dim__n_components': n_features_to_test,\n",
    "        'regressor__alpha': alpha_to_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = [\n",
    "        {'scaler': scalers_to_test,\n",
    "         'reduce_dim': [PCA()],\n",
    "         'reduce_dim__n_components': n_features_to_test,\n",
    "         'regressor__alpha': alpha_to_test},\n",
    "\n",
    "        {'scaler': scalers_to_test,\n",
    "         'reduce_dim': [SelectKBest(f_regression)],\n",
    "         'reduce_dim__k': n_features_to_test,\n",
    "         'regressor__alpha': alpha_to_test}\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n",
      "Final score is:  -5298.26495423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 2160 out of 2160 | elapsed:   33.3s finished\n"
     ]
    }
   ],
   "source": [
    "gridsearch = GridSearchCV(pipe,params, verbose =1).fit(X_train, y_train)\n",
    "print('Final score is: ', gridsearch.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are:  {'reduce_dim': SelectKBest(k=9, score_func=<function f_regression at 0x108ecd620>), 'reduce_dim__k': 9, 'regressor__alpha': 8.0, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}\n"
     ]
    }
   ],
   "source": [
    "print('Best params are: ', gridsearch.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
